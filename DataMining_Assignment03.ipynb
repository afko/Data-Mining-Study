{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build SVC to predict KOSPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pandas.io import data\n",
    "import pandas\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import linear_model\n",
    "import numpy as np\n",
    "from numpy import linalg\n",
    "from scipy import stats\n",
    "import math\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = datetime.datetime(2015, 1, 1)\n",
    "end = datetime.datetime(2016, 10, 31)\n",
    "\n",
    "KOSPI = data.DataReader(\"^KS11\", 'yahoo', start, end)\n",
    "SNP = data.DataReader(\"^GSPC\", 'yahoo', start, end)\n",
    "DJ = data.DataReader(\"^DJI\", 'yahoo', start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D['SNP1']=SNP['Close'].pct_change()\n",
    "D['SNP3']=SNP['Close'].pct_change(periods=3)\n",
    "\n",
    "D['DJ1']=DJ['Close'].pct_change()\n",
    "D['DJ3']=DJ['Close'].pct_change(periods=3)\n",
    "\n",
    "D['KOSPI1']=KOSPI['Close'].pct_change()\n",
    "D['KOSPI3']=KOSPI['Close'].pct_change(periods=3)\n",
    "\n",
    "D = D.dropna()\n",
    "\n",
    "var = D.as_matrix()\n",
    "out=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for i in range(len(var)):\n",
    "    if var[i][4] >= 0 :\n",
    "        output = 1\n",
    "    else :\n",
    "        output = -1\n",
    "    out.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = var[:400]\n",
    "y = out[:400]\n",
    "test_x = var[400:]\n",
    "test_y = out[400:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = SVC(kernel='rbf', gamma=1.0)\n",
    "clf.fit(x,y)\n",
    "print(clf.score(test_x,test_y))\n",
    "\n",
    "\n",
    "\n",
    "clf = SVC(kernel='rbf', gamma=10.0)\n",
    "clf.fit(x,y)\n",
    "print(clf.score(test_x,test_y))\n",
    "\n",
    "clf = SVC(kernel='rbf', gamma=100.0)\n",
    "clf.fit(x,y)\n",
    "print(clf.score(test_x,test_y))\n",
    "\n",
    "\n",
    "clf = SVC(kernel='rbf', gamma=1000.0)\n",
    "clf.fit(x,y)\n",
    "print(clf.score(test_x,test_y))\n",
    "\n",
    "\n",
    "clf = SVC(kernel='poly', gamma=1.0)\n",
    "clf.fit(x,y)\n",
    "print(clf.score(test_x,test_y))\n",
    "\n",
    "\n",
    "clf = SVC(kernel='poly', gamma=10.0)\n",
    "clf.fit(x,y)\n",
    "print(clf.score(test_x,test_y))\n",
    "\n",
    "\n",
    "clf = SVC(kernel='poly', gamma=100.0)\n",
    "clf.fit(x,y)\n",
    "print(clf.score(test_x,test_y))\n",
    "\n",
    "\n",
    "clf = SVC(kernel='poly', gamma=1000.0)\n",
    "clf.fit(x,y)\n",
    "print(clf.score(test_x,test_y))\n",
    "\n",
    "\n",
    "clf = SVC(kernel='poly', gamma=1.0, degree=5)\n",
    "clf.fit(x,y)\n",
    "print(clf.score(test_x,test_y))\n",
    "\n",
    "\n",
    "\n",
    "clf = SVC(kernel='poly', gamma=10.0, degree=5)\n",
    "clf.fit(x,y)\n",
    "print(clf.score(test_x,test_y))\n",
    "\n",
    "\n",
    "\n",
    "clf = SVC(kernel='poly', gamma=100.0, degree=5)\n",
    "clf.fit(x,y)\n",
    "print(clf.score(test_x,test_y))\n",
    "\n",
    "\n",
    "clf = SVC(kernel='poly', gamma=1000.0, degree=5)\n",
    "clf.fit(x,y)\n",
    "print(clf.score(test_x,test_y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate homogeneity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset =open('C:/Users/김성제/Desktop/공부/3학년2학기/Data Mining/Assignment3/two_moons.txt', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data=[]\n",
    "\n",
    "x0=[]\n",
    "x1=[]\n",
    "for line in dataset:\n",
    "    split_line = line.split()\n",
    "    number_line=[float(x) for x in split_line]\n",
    "    if split_line[-1] == '0.0':\n",
    "        x0.append(split_line)\n",
    "    else:\n",
    "        x1.append(split_line)\n",
    "    data.append(number_line)\n",
    "dataset.close()\n",
    "\n",
    "\n",
    "\n",
    "x=[l[:-1] for l in data]\n",
    "y=[l[-1] for l in data]\n",
    "n0=[l[:-1] for l in x0]\n",
    "n1=[l[:-1] for l in x1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def entropy_func(x,y):\n",
    "    return math.log(len(x),2)-math.log(len(y),2)\n",
    "\n",
    "entropy_result = -1*(((1.0*len(n0))/len(x))*entropy_func(n0,x)+(1.0*len(n1)/len(x))*entropy_func(n1,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "ncluster=2\n",
    "hierarchy=AgglomerativeClustering(linkage='complete', n_clusters=ncluster)\n",
    "hierarchy.fit(x)input1=[]\n",
    "input2=[]\n",
    "output=[]\n",
    "for i in data:\n",
    "    x1=i[0]\n",
    "    input1.append(x1)\n",
    "    x2=i[1]\n",
    "    input2.append(x2)\n",
    "\n",
    "output = y\n",
    "D = pd.DataFrame(columns=['x1', 'x2', 'class','cluster'])\n",
    "\n",
    "D['x1']=input1\n",
    "D['x2']=input2\n",
    "D['class']=output\n",
    "D['cluster']=hierarchy.labels_\n",
    "\n",
    "Nck00 = D[(D['class']==0) & (D['cluster']==0)]\n",
    "Nck01 = D[(D['class']==0) & (D['cluster']==1)]\n",
    "Nck10 = D[(D['class']==1) & (D['cluster']==0)] \n",
    "Nck11 = D[(D['class']==1) & (D['cluster']==1)] \n",
    "\n",
    "\n",
    "cluster0 = D[D['cluster']==0]\n",
    "cluster1 = D[D['cluster']==1]\n",
    "\n",
    "\n",
    "\n",
    "conditional_entropy = -1*((1.0*len(Nck00)/len(x))*entropy_func(Nck00,cluster0)+(1.0*len(Nck01)/len(x))*entropy_func(Nck01,cluster1)\n",
    "                          +(1.0*len(Nck10)/len(x))*entropy_func(Nck10,cluster0)+(1.0*len(Nck11)/len(x))*entropy_func(Nck11,cluster1))c\n",
    "\n",
    "input1=[]\n",
    "input2=[]\n",
    "output=[]\n",
    "for i in data:\n",
    "    x1=i[0]\n",
    "    input1.append(x1)\n",
    "    x2=i[1]\n",
    "    input2.append(x2)\n",
    "\n",
    "output = y\n",
    "D = pd.DataFrame(columns=['x1', 'x2', 'class','cluster'])\n",
    "\n",
    "D['x1']=input1\n",
    "D['x2']=input2\n",
    "D['class']=output\n",
    "D['cluster']=hierarchy.labels_\n",
    "\n",
    "Nck00 = D[(D['class']==0) & (D['cluster']==0)]\n",
    "Nck01 = D[(D['class']==0) & (D['cluster']==1)]\n",
    "Nck10 = D[(D['class']==1) & (D['cluster']==0)] \n",
    "Nck11 = D[(D['class']==1) & (D['cluster']==1)] \n",
    "\n",
    "\n",
    "cluster0 = D[D['cluster']==0]\n",
    "cluster1 = D[D['cluster']==1]\n",
    "\n",
    "conditional_entropy = -1*((1.0*len(Nck00)/len(x))*entropy_func(Nck00,cluster0)+(1.0*len(Nck01)/len(x))*entropy_func(Nck01,cluster1)\n",
    "                          +(1.0*len(Nck10)/len(x))*entropy_func(Nck10,cluster0)+(1.0*len(Nck11)/len(x))*entropy_func(Nck11,cluster1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "homogeneity = 1-(conditional_entropy/entropy_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_table(r'C:\\Users\\김성제\\Desktop\\공부\\3학년2학기\\Data Mining\\Assignment 3\\elemapi2.txt', sep='\\t',names=['snum', 'dnum', 'api00', 'api99', 'growth', 'meals', 'ell', 'yr_rnd', 'mobility', 'acs_k3', 'acs_46', 'not_hsg', 'hsg', 'some_col', 'col_grad', 'grad_sch', 'avg_ed', 'full', 'emer', 'enroll', 'mealcat', 'collcat'])\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "x = df[['ell', 'meals', 'acs_k3', 'acs_46', 'growth', 'full' , 'emer', 'enroll']]\n",
    "y = df['api00']\n",
    "y = pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "pca = PCA(n_components=4)\n",
    "pca.fit(x)\n",
    "pca.n_components_\n",
    "pca.components_\n",
    "\n",
    "pca.explained_variance_\n",
    "pca.explained_variance_ratio_\n",
    "\n",
    "x_pca = pca.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lin = linear_model.LinearRegression()\n",
    "\n",
    "lin.fit(x_pca,y)\n",
    "lin.coef_\n",
    "lin.intercept_\n",
    "y_pred = lin.predict(x_pca)\n",
    "x_pca = pd.DataFrame(x_pca)\n",
    "\n",
    "\n",
    "x_pca['intercept'] = np.repeat(1, len(x_pca))\n",
    "\n",
    "e = y-y_pred\n",
    "input_mat = np.matrix(x_pca[['intercept',0,1,2,3]])\n",
    "output_mat = np.matrix(df['api00']).T\n",
    "XtX = input_mat.T*input_mat\n",
    "inv_XtX = linalg.inv(XtX)\n",
    "coef = inv_XtX*input_mat.T*output_mat\n",
    "coef = np.array(coef)\n",
    "\n",
    "\n",
    "MSE =sum((y.values-y_pred)**2)/(len(x)-2)\n",
    "SE = np.multiply(MSE,inv_XtX)\n",
    "MAT_SE = np.multiply(MSE, inv_XtX)\n",
    "\n",
    "\n",
    "DF_SE=[]\n",
    "for i in range(5):\n",
    "    SE = math.sqrt(MAT_SE.item((i,i)))\n",
    "    DF_SE.append(SE)\n",
    "\n",
    "DF_SE\n",
    "\n",
    "tval_inter=lin.intercept_/DF_SE[0]\n",
    "tvalue = lin.coef_/DF_SE[1:]\n",
    "\n",
    "pvalue = (1-stats.t.cdf(abs(tvalue),len(x_pca)-5))*2\n",
    "pvalue_inter = (1-stats.t.cdf(abs(tval_inter),len(x_pca)-4))*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "y_mean = y.mean().values\n",
    "y_mean\n",
    "SSR = sum((y_pred-y_mean)**2)\n",
    "SSR\n",
    "\n",
    "y_values = y.values\n",
    "SSE = sum((y_pred-y_values)**2)\n",
    "SSE\n",
    "\n",
    "y = np.array(y)\n",
    "SST = sum((y-y_mean)**2)\n",
    "SST\n",
    "\n",
    "p = 4\n",
    "len(x_pca)-p-1\n",
    "\n",
    "MSR = SSR/p\n",
    "MSR\n",
    "MSE = SSE/(len(x_pca)-p-1)\n",
    "MSE\n",
    "F = MSR/MSE\n",
    "F\n",
    "\n",
    "F_pvalue = 1-stats.f.cdf(F,p,len(x_pca)-p-1)\n",
    "F_pvalue\n",
    "\n",
    "\n",
    "#R, adR\n",
    "r_square = SSR/SST\n",
    "r_square\n",
    "\n",
    "ad_r_square = 1-((len(x_pca)-1)/(len(x_pca)-p-1)*(1-r_square))\n",
    "ad_r_square"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
